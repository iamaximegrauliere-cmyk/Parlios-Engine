# orchestrateur-IA-personnalise

Orchestrateur **multi-agents** ultra-personnalisÃ© (profil dynamique + RAG + citations) basÃ© sur ta mÃ©thode.

## ğŸš€ DÃ©marrage rapide
```bash
# 1) (Optionnel) crÃ©er un venv
python -m venv .venv && source .venv/bin/activate

# 2) Installer les dÃ©pendances
pip install -r requirements.txt

# 3) Lancer l'API (FastAPI + Uvicorn)
uvicorn src.app.main:app --reload --port 8080

# 4) Construire l'index RAG (si tu as des docs)
python scripts/build_index.py --input ./data/docs --index ./data/index.pkl
```

## ğŸ“¦ Structure
```
src/
  app/           # FastAPI endpoints
  orchestrator/  # Cerveau : planification, brief, routing
  agents/        # Agents spÃ©cialisÃ©s (briefing, recherche, production, vÃ©rif)
  rag/           # Ingestion/index/retrieval + citations
  memory/        # Profil utilisateur dynamique + mÃ©moire courte/longue
  schemas/       # Pydantic models (Brief, Profil, etc.)
configs/         # YAML (persona, thinking framework, config serveur)
prompts/         # Prompts systÃ¨me/refus (se basent sur les YAML)
data/            # examples.jsonl, docs, index
scripts/         # scripts utilitaires (build index, eval)
tests/           # tests unitaires (base)
docs/            # notes dâ€™archi, diagrammes
```

## ğŸ”§ Endpoints clÃ©s
- `POST /ask` â†’ prend `question` (+ option profil) et orchestre agents â†’ **rÃ©ponse avec citations**.
- `POST /brief` â†’ transforme une demande floue en **Brief JSON** (actionnable).
- `POST /run` â†’ exÃ©cute un **Brief** existant (pipeline agents).
- `POST /verify` â†’ vÃ©rifie une rÃ©ponse par rapport au **Brief**.
- `POST /profile/event` â†’ ingÃ¨re un signal faible (ajuste le profil).

## ğŸ§  Personnalisation
- Modifie `configs/persona.yaml` et `configs/thinking_framework.yaml`.
- Ajoute 20â€“50 paires dans `data/examples.jsonl` (style & rÃ©flexes).
- Place tes docs dans `data/docs/` puis construis lâ€™index (`scripts/build_index.py`).

## âœ… Citations obligatoires
Le module RAG attache systÃ©matiquement `source` (fichier + page/section) aux extraits utilisÃ©s.
Lâ€™orchestrateur **refuse** dâ€™Ã©mettre des affirmations factuelles non sourcÃ©es (ou marque `[Ã  valider]`).

## ğŸ§ª Ã‰valuation
Utilise `scripts/evaluate.py` (exactitude@k, hallucinations, utilitÃ©, latence p95).


---
## âœ… 100% GitHub Ready

- Repo autoâ€‘suffisant (pas d'appels externes obligatoires).
- Agents **Clarifier** et **Metaâ€‘Reflect** inclus et activÃ©s.
- Script `scripts/generate_dashboard.py` pour produire `docs/dashboard.md`.
- Dossier `prompts/gold/` pour centraliser tes prompts exemplaires.
- Dossier `ventures/ventures.json` pour cartographier tes idÃ©es/projets.

### (Optionnel) GitHub Actions
CrÃ©e `.github/workflows/ci.yml` pour:
- lancer tests,
- gÃ©nÃ©rer le dashboard,
- publier les artefacts.


### Construire l'index RAG (TF-IDF local, lÃ©ger)
```bash
python scripts/build_index.py --input ./data/docs --index ./data/index.pkl
```


## v4 â€” NouveautÃ©s
- **RAG Hybride (TFâ€‘IDF + BM25)** avec *rerank* optionnel.
- **Splitters** hiÃ©rarchiques (`src/rag/splitters.py`).
- **Ã‰valuation rapide** (`eval/run_eval.py` + `eval/dataset.jsonl`) â†’ `docs/eval_report.json`.
- **Docker multiâ€‘stage** + **CI** avec cache pip et **smoke eval**.
- **Docs** : `docs/architecture.md`, `docs/operational-playbook.md`.
